{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tiktoken\n",
    "import openai\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  여기서부터 시작!!!!!!!!!!!\n",
    "### 여기서부터 df=pd.read_csv(\"파일이름.csv\") 로 내가 만든 데이터를 불러오기. 파일 열의 형식은 `title`, `content`이어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".././food_eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df['n_tokens'] = df['content'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df.n_tokens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 2000\n",
    "def split_into_many(text, max_tokens = max_tokens):\n",
    "\n",
    "    # 일단 문장으로 쪼개기\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # 문장마다 몇 토큰 들어가는지 세어 주기.\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # 문장의 토큰 수와 현재까지의 토큰 수의 합이 최대 토큰 수를 초과하면, 해당 청크를 청크 목록에 추가하고 청크 및 현재까지의 토큰 수를 초기화한다.\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\". \".join(chunk) + \".\")\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened = []\n",
    "# 데이터 프레임 순회하기\n",
    "for row in df.iterrows():\n",
    "\n",
    "    # If the content is None, go to the next row\n",
    "    if row[1]['content'] is None:\n",
    "        continue\n",
    "\n",
    "    # If the number of tokens is greater than the max number of tokens, split the content into chunks\n",
    "    if row[1]['n_tokens'] > max_tokens:\n",
    "        shortened += split_into_many(row[1]['content'])\n",
    "    \n",
    "    # Otherwise, add the content to the list of shortened texts\n",
    "    else:\n",
    "        shortened.append( row[1]['content'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_large_text(large_text, max_tokens=2000):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokenized_text = enc.encode(large_text)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in tokenized_text:\n",
    "        current_chunk.append(token)\n",
    "        current_length += 1\n",
    "\n",
    "        if current_length >= max_tokens:\n",
    "            chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "df['splitted_content'] = df['content'].apply(split_large_text)\n",
    "df = df.explode(\"splitted_content\")\n",
    "df['spllitted_n_tokens'] = df['splitted_content'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df = df.reset_index( drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['title','splitted_content', 'spllitted_n_tokens']].rename(columns={'splitted_content':'content', 'spllitted_n_tokens':'n_tokens'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_info(row):\n",
    "    title = \" \".join(row['title'].split(\"-\"))\n",
    "\n",
    "    content = row['content']   #챗gpt 물어봐서 추가한 코드\n",
    "    \n",
    "    combined = [f\"title: {title}\", f\"content: \\n{content}\"]\n",
    "    combined = \"\\n\\n###\\n\\n\".join(combined)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "df[\"combined\"] = df.apply(combine_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "#    text = text.replace(\"\\n\", \" \")\n",
    "#    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"embedding\"] = df.combined.apply(get_embedding)\n",
    "# df.to_pickle(\"../../processed/food_eng.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../processed/food_eng.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  여기서부터는 테스트 코드!!!!!!!!!!!!!!!!!!!\n",
    "### 실제 개발환경에서 배포할 때 확인할 목적!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../processed/food_eng.pkl\")\n",
    "def create_context(\n",
    "    question, df, max_len=3000\n",
    "):\n",
    "    q_embeddings = client.embeddings.create(input=question, model='text-embedding-ada-002').data[0].embedding\n",
    "    df[\"distances\"] = df[\"embedding\"].apply(lambda x: cosine(q_embeddings, x))\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        returns.append(row[\"combined\"])\n",
    "    return \"\\n\\n===\\n\\n\".join(returns)\n",
    "\n",
    "\n",
    "def answer_question(\n",
    "    df,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    question=\"Tell me about Tumbler Beer\",\n",
    "    max_len=3000,\n",
    "    debug=False,\n",
    "):\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "    )\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\n\"},\n",
    "                {\"role\": \"user\", \"content\": f\"context: {context}\\n\\n---\\n\\n Question: {question}, 한국어로 대답해줘.\"}\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tumbler Beer의 주소는 서울 강남구 테헤란로 20길 15입니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"Tumbler Beer의 주소를 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tumbler Beer의 운영 시간은 주중에는 오후 4시부터 새벽 3시까지이고, 토요일에는 오후 4시부터 밤 12시까지입니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"Tumbler Beer의 운영 시간를 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지하철 2호선 역삼역 3번 출구에서 이동할 수 있습니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"Tumbler Beer의 교통 정보를 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
